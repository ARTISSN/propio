# ─── Global Paths & Model ─────────────────────────────────────────────────────
base_dir: data/characters              # where your mesh & reference dirs live
output_dir: models/lora_weights        # where to write checkpoints
sdxl_model_path: stabilityai/stable-diffusion-xl-base-1.0

# ─── Resolution & Progression ────────────────────────────────────────────────
data:
  initial_resolution: 256                # start here for warm-up
  full_resolution:    512                # later for fine detail
  progressive_switch_epoch: 10           # when to switch to full_resolution

# ─── Epoch Boundaries ────────────────────────────────────────────────────────
schedule:
  spatial:
    num_epochs:         200              # total spatial epochs
    perceptual_start:   0                # epoch to start AuraFace & LPIPS
    gan_start:          0                # epoch to start adversarial loss
    curriculum_step_frac: 0.1

# ─── Diffusion Settings ──────────────────────────────────────────────────────
diffusion:
  num_timesteps: 20                      # number of denoising steps for both training and inference
  denoising_strength: 0.8
  prompt: "<rrrdaniel>"                  # text prompt for conditioning
  guidance_scale: 7.5                    # classifier-free guidance scale

# ─── Spatial-Stage Loss Weights & Frequencies ─────────────────────────────────
loss_spatial:
  lambda_mse:    1.0                     # latent MSE
  lambda_patch:  0.3                     # single-patch MSE
  lambda_id:     1                    # AuraFace identity
  lambda_perceptual:  1                     # LPIPS (256², see below)
  lambda_adv:    1                       # GAN generator weight
  gan_frequency: 3                       # every N steps for both D & G
  perceptual_frequency: 2                     # every N steps for LPIPS
  patch_ratio: 0.2

# ─── Temporal-Stage Loss Weights & Settings ──────────────────────────────────
loss_temporal:
  pairs_per_epoch:     5                 # K in latent-phase batching
  lambda_id:           0.50              # AuraFace identity in temporal
  lambda_lpips:        0.10              # LPIPS in pixel-polish
  lpips_frequency:     1                 # every N frames/steps

# ─── LoRA / Model Config ─────────────────────────────────────────────────────
model:
  lora_rank:       4
  lora_alpha:     32
  lora_dropout:   0.1
  ema_decay:      0.9999
  target_modules:
    - to_q
    - to_k
    - to_v
    - to_out.0
    - ff.net.0.proj
    - ff.net.2

# ─── Training & Optimization ─────────────────────────────────────────────────
training:
  batch_size:                   1
  gradient_accumulation_steps:  4
  learning_rate:                1e-4
  warmup_ratio:                 0.0
  max_train_steps:              10000
  spatial_early_stop_patience:  10
  temporal_early_stop_patience: 3

optimization:
  mixed_precision:        bf16
  use_8bit_adam:          true
  gradient_checkpointing: true
  enable_xformers:        false

# ─── Debug / Logging ──────────────────────────────────────────────────────────
debug:
  enabled: false
  log_steps:      10
  save_steps:     500
  preview_steps:  50
